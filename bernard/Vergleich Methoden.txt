Bernard:

- gesamter Log wird aus csv-Datei eingelesen
- Sortierung des Logs nach 1. journey_id und 2. timestamp
- Ermittlung der time_diff zwischen den Events (ist in den Logs eigtl bereits gegeben)
- Anzahl k der Cases/Traces ist bekannt (synthetic: 1000 = k)

TAP:
- an den Stellen der k größten Zeitabstände wird gecuttet

LCPAP:
- Name der jeweils nächsten Aktivität wird ermittelt und als Paar mit dem Vorgänger in der Spalte 'pair' abgespeichert (z.B. A_B)
- Ermittlung der durchschnittlichen time_diff für jedes Paar
- Spalte 'MPTAP' als Zuweisung des durchschnittlichen Wertes eines jeden Paares zum ersten Teil des Paars
- an den Stellen der k größten 'MPTAP'-Werte wird gecuttet



Mein Ansatz:

- gesamter Log wird aus csv-Datei in einen vorübergehenden dataframe eingelesen
- Sortierung des Logs nach 1. journey_id und 2. timestamp
- Anzahl der Cases/Traces ist zwar bekannt, wird aber nicht verwendet

TAP:
- neuer, leerer dataframe wird erzeugt
- vorübergehender dataframe wird mit einer for-Schleife zeilenweise eingelesen
- mean wird auf den ersten time_diff-Wert gesetzt
- var = st_dev = 0
- Formel: if aktueller time_diff-Wert > mean + st_dev * Faktor f, dann wird an der Stelle gecuttet (f variabel, wurde mit vielen Parametern 0 < f < 1 getestet)
- mean wird mit inkrementeller Formel aktualisiert
- var wird mit inkrementeller Formel aktualisiert -> st_dev = sqrt(var)
- aktuelle Zeile wird an den neuen dataframe angehängt

LCPAP:
- neuer, leerer dataframe wird erzeugt
- vom vorübergehenden dataframe werden mit einer for-Schleife zwei Zeilen eingelesen
- so kann der Name der jeweils nächsten Aktivität ermittelt und als Paar mit dem Vorgänger in der Spalte 'pair' abgespeichert werden (z.B. A_B)
- mean wird auf den ersten time_diff-Wert gesetzt
- var = st_dev = 0
- Häufigkeit des Auftretens und mean der time_diff wird für jedes Paar in einem gesammelten dict gespeichert
- wenn ein Paar auftritt, wird ein neues Paar mit mean = aktueller time_diff-Wert der ersten der beiden Zeilen eingetragen (Paar kam noch nicht vor) 
oder mean des Paares wird mit inkrementeller Formel aktualisiert (Paar kam bereits vor)
- aktualisierter mean-Wert des aktuellen Paares wird mit dem mean über alle bisherigen mean-Werte der Paare verglichen
- Formel: if mean_wert des Paares > mean + st_dev * Faktor f, dann wird an der Stelle gecuttet (f variabel, wurde mit vielen Parametern 0 < f < 1 getestet)
- mean über alle bisherigen mean-Werte der Paare wird mit inkrementeller Formel aktualisiert
- var über alle bisherigen mean-Werte der Paare wird mit inkrementeller Formel aktualisiert -> st_dev = sqrt(var)
- erste der beiden Zeilen wird an den neuen dataframe angehängt


Evaluation der Ergebnisse:
- TP: Menge der korrekt erkannten Cases (Spalte TAP/MPTAP verglichen mit Spalte 'last_trace'/ground truth)
- FP: Menge der erkannten Cuts, die aber eigtl keine Cuts zwischen neuen Cases darstellen
- FN: Menge der Cuts zwischen Cases, die aber nicht erkannt wurden

- Precision (Pr): TP/(TP+FP)
- Recall (Re): TP/(TP+FN)
- F1-score: 2*Pr*Re/(Pr+Re)




Leno:

- gesamter Log wird aus csv in Java eingelesen und als ein gesamter String abgespeichert
- alle OS-Clipboard Copy Events werden manuell gelöscht
- alle getCell/editCell/getRange Events mit anschließendem copy werden zu einem Event (copyCell) zusammengefasst
- DFG wird mithilfe der Eventliste erstellt
- aus dem DFG wird dann ein Dominator Tree erstellt
- domTree.analyse() mit dem Header des Dominator Trees
- Liste der Loops wird analysiert und die Back-edges werden ermittelt
- jede Back-edge signalisiert das Ende eines Cases, wonach gecuttet wird
- so werden die Cases ermittelt und getrennt